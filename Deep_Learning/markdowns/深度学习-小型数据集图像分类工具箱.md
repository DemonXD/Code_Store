### 使用kaggle的猫狗分类数据集，泛化一个工具箱

**工具集包含猫狗各12500张训练数据集，和各6250张测试数据集，并且图片尺寸不统一**

- 使用小数据集进行训练和测试

  - 训练数据集：猫：1000， 狗：1000
  - 验证数据集：猫：500， 狗：500
  - 测试数据集：猫：500， 狗：500

- 问题分析：

  - 首先这个网络最后是执行一个二分类问题，所以最后一层是用sigmoid激活函数

  - 输入尺寸需要进行统一，这里选择150x150x3

  - 由于问题比较复杂，所以网络相比MNIST要增加几层，这里选用：

    > Conv2D(32, (3, 3))
    >
    > MaxPooling2D((2, 2))
    >
    > Conv2D(64, (3, 3))
    >
    > MaxPooling2D((2, 2))
    >
    > Conv2D(128, (3, 3))
    >
    > MaxPooling2D((2, 2))
    >
    > Conv2D(128, (3, 3))
    >
    > MaxPooling2D((2, 2))
    >
    > Flatten()
    >
    > Dense(512)
    >
    > Dense(1, "sigmoid")
    >
    > 建模后使用model.summary()，可以看到最后一层池化结束时，特征图的尺寸为7x7x128，
    >
    > 展平后送到512大小的Dense层，总的参数数量达到了3211776

  - 模型编译时，选用RMSprop优化器，learning_rate设置为1e-4(0.0001)

  - 整个基于keras的模型如下：

    > ```Python
    > model = models.Sequential()
    > model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))
    > model.add(layers.MaxPooling2D((2, 2)))
    > model.add(layers.Conv2D(64, (3, 3), activation='relu'))
    > model.add(layers.MaxPooling2D((2, 2)))
    > model.add(layers.Conv2D(128, (3, 3), activation='relu'))
    > model.add(layers.MaxPooling2D((2, 2)))
    > model.add(layers.Conv2D(128, (3, 3), activation='relu'))
    > model.add(layers.MaxPooling2D((2, 2)))
    > model.add(layers.Flatten())
    > model.add(layers.Dense(512, activation='relu'))
    > model.add(layers.Dense(1, activation="sigmoid"))
    > 
    > model.compile(
    >     optimizer=optimizers.RMSprop(lr=0.0001),
    >     loss="binary_crossentropy",
    >     metrics=["accuracy"]
    > )
    > ```

- 数据预处理：

  - 读取图像文件
  - 将JEPG文件解码为RGB像素网格
  - 将像素网格转换为浮点数张量
  - 将像素值(0~255)缩放到[0~1]区间，让神经网络处理较小的输入值可以减轻压力

  > keras提供了图片处理的工具，keras.preprocessing.image
  >
  > ```Python
  > from keras.preprocessing.image import ImageDataGenerator
  > train_datagen = ImageDataGenerator(rescale=1./255) # 将所有图像乘以1/255
  > train_generator = train_datagen.flow_from_directory(
  >     train_dir,						# 图像地址
  >     target_size=(150, 150),			# 目标大小
  >     batch_size=20,					
  >     class_mode='binary'				# 因为使用binary_crossentropy。所以使用二进制标签
  > )
  > ```

- 训练：

  > ```PYthon
  > history = model.fit_generator(
  >     train_generator,
  >     steps_per_epoch=100,
  >     epochs=30,
  >     validation_data=validation_generator,
  >     validation_steps=50
  > )
  > # 根据训练完成的数据，可以得知，验证精度到达73左右，就不再升高了，而训练精度却一直在增加，并且验证损失，在5个epochs后，就开始保持不变了，而训练损失一直在降低，由此可知，训练发生了过拟合
  > ```
  - 由于数据量少，造成了训练的过拟合，此处使用一种对于小数据集的增强方法，数据增强，其作用是利用多种能够生成可信图像的随即变换来增加训练样本，在keras中ImageDataGenerator就有这个功能，通过调整其部分参数就可以达到要求：

  > ```Python
  > # 数据增强
  > datagen = ImageDataGenerator(
  >     rotation_range=40,           # 图像随机旋转的角度范围(0~180)
  >     width_shift_range=0.2,       # 图像在水平方向上平移的范围（比例）
  >     height_shift_range=0.2,      # 图像在垂直方向上平移的范围（比例）
  >     shear_range=0.2,             # 随机错切变换的角度
  >     zoom_range=0.2,              # 图像随机缩放的范围
  >     horizontal_flip=True,        # 随机将一半图像水平翻转
  >     fill_mode="nearest"          # 填充新创建像素的方法
  > )
  > ```
  - 虽然使用数据增强可以帮助缓解过拟合，但是无法完全消除，所以在Dense(512)之前，加一层Dropout层，进行一次随机丢弃

  - 此时新的网络：

    > ```python
    > model = models.Sequential()
    > model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))
    > model.add(layers.MaxPooling2D((2, 2)))
    > model.add(layers.Conv2D(64, (3, 3), activation='relu'))
    > model.add(layers.MaxPooling2D((2, 2)))
    > model.add(layers.Conv2D(128, (3, 3), activation='relu'))
    > model.add(layers.MaxPooling2D((2, 2)))
    > model.add(layers.Conv2D(128, (3, 3), activation='relu'))
    > model.add(layers.MaxPooling2D((2, 2)))
    > model.add(layers.Flatten())
    > model.add(layers.Dropout(0.5))
    > model.add(layers.Dense(512, activation='relu'))
    > model.add(layers.Dense(1, activation="sigmoid"))
    > 
    > model.compile(
    >     optimizer=optimizers.RMSprop(lr=0.0001),
    >     loss="binary_crossentropy",
    >     metrics=["acc"]
    > )
    > ```

  - 对输入数据进行数据增强：

    > ```Python
    > train_datagen = ImageDataGenerator(
    >     rescale=1./255,
    >     rotation_range=40,           # 图像随机旋转的角度范围(0~180)
    >     width_shift_range=0.2,       # 图像在水平方向上平移的范围（比例）
    >     height_shift_range=0.2,      # 图像在垂直方向上平移的范围（比例）
    >     shear_range=0.2,             # 随机错切变换的角度
    >     zoom_range=0.2,              # 图像随机缩放的范围
    >     horizontal_flip=True,        # 随机将一半图像水平翻转
    >     fill_mode="nearest"          # 填充新创建像素的方法
    > )
    > train_generator = train_datagen.flow_from_directory(
    >     train_dir,
    >     target_size=(150, 150),
    >     batch_size=32,
    >     class_mode='binary')
    > history = model.fit_generator(
    >     train_generator,
    >     steps_per_epoch=100,
    >     epochs=100,
    >     validation_data=validation_generator,
    >     validation_steps=50
    > )
    > ```
    >
    > 

- 使用数据增强和dropout，可以在一定程度上解决过拟合的问题，但是如果想要再进一步提升网络的精度，除了使用无限量的训练集，还有一种办法就是使用**预训练网络**， 预训练网络是一个保存好的网络，之前在大型数据集上训练好。使用预训练网络有两种方法：**特征提取**和**微调模型**。

  - **特征提取**：

    - 使用之前昂罗学到的表示来从新样本中提取出有趣的特征，然后将这些特征输入一个新的分类器，从头开始训练。
    - 图像分类的卷积神经网络包含两部分，首先是一些列池化层和卷积层，然后是一个密集连接分类器，第一部分叫做模型的**卷积基**，对于卷积神经网络而言，特征提取就是去除之前训练好的网络的卷积基，在上面运行新数据，然后在输出上面训练一个新的分类器。

    > keras 中内置了一些之前网络的模型：VGG16，VGG19等。
    >
    > ```Python
    > from keras.applications import VGG16
    > conv_base = VGG16(
    > 	weights='imagenet', 		# 指定模型初始化的权重检查点
    >     include_top=False, 			# 是否需要密集连接分类器，如果是自定义的分类器，这里选择False
    >     input_shape=(150, 150, 3)	# 指定输入数据的尺寸
    > )
    > 
    > # 查看网络层级
    > conv_base.summary()
    > ```

    - 添加自定义密集分类器：

      - 在自己的数据集上运行卷积基，将输出保存成硬盘中的Numpy数组，然后用这个数据作为输入，输入到独立的密集连接分类器中，这种方法速度快，计算代价低，因为对于每个输入图像只需要运行一次卷积基，而卷积基是目前流程中计算代价最高的，但是使用这种方法，无法使用数据增强

        > ```python
        > # 处理原始数据
        > base_dir = r"D:\Practice_Code\Python\DEEP_LEARNING\toolsets\small_pictures"
        > train_dir = os.path.join(base_dir, "train")
        > validation_dir = os.path.join(base_dir, "validation")
        > test_dir = os.path.join(base_dir, "test")
        > 
        > datagen = ImageDataGenerator(
        >     rescale=1./255
        > )
        > batch_size = 20
        > def extract_features(directory, sample_count):
        >     features = np.zeros(shape=(sample_count, 4, 4, 512))
        >     labels = np.zeros(shape=(sample_count))
        >     generator = datagen.flow_from_directory(
        >         directory,
        >         target_size=(150, 150),
        >         batch_size=batch_size,
        >         class_mode="binary"
        >     )
        >     i = 0
        >     for inputs_batch, labels_batch in generator:
        >         features_batch = conv_base.predict(inputs_batch)
        >         features[i * batch_size : (i+1) * batch_size] = features_batch
        >         labels[i*batch_size: (i+1)*batch_size] = labels_batch
        >         i+=1
        >         if i*batch_size >= sample_count:
        >             break
        >     return features, labels
        > 
        > train_features, train_labels = extract_features(train_dir, 2000)
        > validation_features, validation_labels = extract_features(validation_dir, 1000)
        > test_features, test_labels = extract_features(test_dir, 1000)
        > 
        > # 展平后，可以将数据塞入密集连接分类器中
        > train_features = np.reshape(train_features, (2000, 4 * 4 * 512))
        > validation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))
        > test_features = np.reshape(test_features, (1000, 4 * 4 * 512))
        > 
        > from keras import models, layers, optimizers
        > 
        > model = models.Sequential()
        > model.add(layers.Dense(256, activation='relu', input_dim=(4 * 4 * 512)))
        > model.add(layers.Dropout(0.5))
        > model.add(layers.Dense(1, activation="sigmoid"))
        > 
        > model.compile(
        >     optimizer=optimizers.RMSprop(lr=2e-5),
        >     loss="binary_crossentropy",
        >     metrics=["acc"]
        > )
        > history = model.fit(
        >     train_features, train_labels,
        >     epochs=30, batch_size=20,
        >     validation_data=(validation_features, validation_labels))
        > ```

      - 在顶部添加Dense层来扩展，并在输入数据上端到端的运行整个模型，这样可以使用数据增强，但是这种方法的计算代价太大

  